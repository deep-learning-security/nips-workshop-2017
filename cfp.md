---
layout: page
title: Machine Learning and Computer Security Workshop
---

# Call for Paper

## Overview

While traditional computer security relies on well-defined attack
models and proofs of security, a science of security for machine
learning systems has proven more elusive. This is due to a number
of obstacles, including (1) the highly varied angles of attack
against ML systems, (2) the lack of a clearly defined attack
surface (because the source of the data analyzed by ML systems is
not easily traced), and (3) the lack of clear formal definitions
of security that are appropriate for ML systems. At the same
time, security of ML systems is of great import due the recent
trend of using ML systems as a line of defense against malicious
behavior (e.g., network intrusion, malware, and ransomware), as
well as the prevalence of ML systems as parts of sensitive and
valuable software systems (e.g. sentiment analyzers for
predicting stock prices). This workshop will bring together
experts from the computer security and machine learning
communities in an attempt to highlight recent work in this area,
as well as to clarify the foundations of secure ML and chart out
important directions for future work and cross-community
collaborations.

## Topics

We invite submissions on any aspect of machine learning that
relates to computer security. This includes, but is not limited
to:

* Case studies of machine learning used in cyber security, such as detection of spam, sybils, or malicious URLs
* Whitepapers proposing or building on formal threat models and definitions of security
* Training time attacks (e.g., data poisoning)
* Adversarial examples at test time
* Model stealing (e.g., for reconnaissance of a system before mounting an attack)
* Theoretical foundations of adversarially robust learning
* Formal verification of machine learning systems
* Identifying bugs in machine learning systems, especially if they present security vulnerabilities
* Strategic analysis of present or future security / misuse risks and how to prioritize them

Submissions should have a clear explanation of their relationship
to security, for instance by describing an [attack model](https://en.wikipedia.org/wiki/Attack_model) and the ways
in which the submitted work addresses such attacks. While not mandatory,
submissions are encouraged to take special care in facilitating
reproducibility of research results (e.g., by open-sourcing their code).

## Submissions

<span style="color:red">The [submission site](https://easychair.org/conferences/?conf=mlsec17) is open!</span>

We accept two types of submissions:

+ **Posters:** We accept submissions on novel results. The submissions should be formated using
a template from any major conferences (NIPS, ICML, etc.). A maximal of 4 pages are allowed for this type of
submission
+ **Contributed talks:** We also accept papers that have already been published. We do not have a page limit
on this type of submissions. In the submission site, please use the **Keyword** field to provide the information
on the venue where the submission was originally published.

We employ two rounds of rolling deadlines:
+ **Round 1**: deadline for submission **October 22th, 2017**; notification **November 3rd, 2017**
+ **Round 2**: deadline for submission **November 3rd, 2017**; notification **November 17rd, 2017**

Contact [Chang Liu](<mailto:liuchang@eecs.berkeley.edu>) for any questions.

## Criteria

A small program committee will review all submissions. Our decisions will be made only based on their relevance
to the topics of the workshop. For technical communications, the novelty will also be considered.

## Best Paper Award

<span style="color:red">We will present a best paper award ($500) to the best technical communication paper!</span>

## Program Committee

Nicholas Carlini

Xinyun Chen

Bo Li

Chang Liu (chair)

Nicolas Papernot

Jacob Steinhardt


## Links

[Back to main page](index.md)
